{"cells":[{"cell_type":"markdown","id":"b233a58d","metadata":{"id":"b233a58d"},"source":["# <font color=darkblue> Machine Learning model deployment with Flask framework</font>"]},{"cell_type":"markdown","id":"2c4b2479","metadata":{"id":"2c4b2479"},"source":["## <font color=Blue>Used Cars Price Prediction Application</font>"]},{"cell_type":"markdown","id":"bad7f286","metadata":{"id":"bad7f286"},"source":["### Objective:\n","1. To build a Machine learning regression model to predict the selling price of the used cars based on the different input features like fuel_type, kms_driven, type of transmission etc.\n","2. Deploy the machine learning model with the help of the flask framework."]},{"cell_type":"markdown","id":"3c741642","metadata":{"id":"3c741642"},"source":["### Dataset Information:\n","#### Dataset Source: https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho?select=CAR+DETAILS+FROM+CAR+DEKHO.csv\n","This dataset contains information about used cars listed on www.cardekho.com\n","- **Car_Name**: Name of the car\n","- **Year**: Year of Purchase\n","- **Selling Price (target)**: Selling price of the car in lakhs\n","- **Present Price**: Present price of the car in lakhs\n","- **Kms_Driven**: kilometers driven\n","- **Fuel_Type**: Petrol/diesel/CNG\n","- **Seller_Type**: Dealer or Indiviual\n","- **Transmission**: Manual or Automatic\n","- **Owner**: first, second or third owner\n"]},{"cell_type":"markdown","id":"a340f92c","metadata":{"id":"a340f92c"},"source":["### 1. Import required libraries"]},{"cell_type":"code","execution_count":null,"id":"DekbG2Sm7L00","metadata":{"id":"DekbG2Sm7L00"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"markdown","id":"38a2da95","metadata":{"id":"38a2da95"},"source":["### 2. Load the dataset"]},{"cell_type":"code","execution_count":1,"id":"LS5P5wps7MOv","metadata":{"id":"LS5P5wps7MOv"},"outputs":[],"source":["import pandas as pd\n","\n","# Step 3: Load the dataset\n","\n","file_path = 'C:/Users/hp/Downloads/car+data.csv'\n","\n","# Load the dataset\n","df = pd.read_csv(file_path)\n","\n"]},{"cell_type":"markdown","id":"26ecd9c6","metadata":{"id":"26ecd9c6"},"source":["### 3. Check the shape and basic information of the dataset."]},{"cell_type":"code","execution_count":2,"id":"wd8XSTpf7Mng","metadata":{"id":"wd8XSTpf7Mng"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of the dataset: (301, 9)\n","\n","Basic Information about the dataset:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 301 entries, 0 to 300\n","Data columns (total 9 columns):\n"," #   Column         Non-Null Count  Dtype  \n","---  ------         --------------  -----  \n"," 0   Car_Name       301 non-null    object \n"," 1   Year           301 non-null    int64  \n"," 2   Selling_Price  301 non-null    float64\n"," 3   Present_Price  301 non-null    float64\n"," 4   Kms_Driven     301 non-null    int64  \n"," 5   Fuel_Type      301 non-null    object \n"," 6   Seller_Type    301 non-null    object \n"," 7   Transmission   301 non-null    object \n"," 8   Owner          301 non-null    int64  \n","dtypes: float64(2), int64(3), object(4)\n","memory usage: 21.3+ KB\n","None\n"]}],"source":["import pandas as pd\n","\n","# Correcting the file path\n","file_path = r'C:/Users/hp/Downloads/car+data.csv'\n","\n","# Load the dataset\n","df = pd.read_csv(file_path)\n","\n","# Check the shape of the dataset\n","print(\"Shape of the dataset:\", df.shape)\n","\n","# Display basic information about the dataset\n","print(\"\\nBasic Information about the dataset:\")\n","print(df.info())\n"]},{"cell_type":"markdown","id":"06991b14","metadata":{"id":"06991b14"},"source":["### 4. Check for the presence of the duplicate records in the dataset? If present drop them"]},{"cell_type":"code","execution_count":3,"id":"-u5XA5d47Nbe","metadata":{"id":"-u5XA5d47Nbe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Duplicate records found. Dropping duplicates...\n","Duplicates dropped. Shape of the dataset: (299, 9)\n"]}],"source":["import pandas as pd\n","\n","# Load the dataset\n","file_path = \"C:/Users/hp/Downloads/car+data.csv\"\n","df = pd.read_csv(file_path)\n","\n","# Check for duplicate records\n","duplicate_rows = df[df.duplicated()]\n","\n","if not duplicate_rows.empty:\n","    print(\"Duplicate records found. Dropping duplicates...\")\n","    # Drop duplicates\n","    df.drop_duplicates(inplace=True)\n","    print(\"Duplicates dropped. Shape of the dataset:\", df.shape)\n","else:\n","    print(\"No duplicate records found.\")\n","\n","# Optionally, you can save the cleaned dataset back to a file if needed\n","# df.to_csv(\"cleaned_car_data.csv\", index=False)\n"]},{"cell_type":"markdown","id":"367efc0b","metadata":{"id":"367efc0b"},"source":["### 5. Drop the columns which you think redundant for the analysis."]},{"cell_type":"code","execution_count":6,"id":"gPMZesyr7OHb","metadata":{"id":"gPMZesyr7OHb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original columns:\n","Index(['Car_Name', 'Year', 'Selling_Price', 'Present_Price', 'Kms_Driven',\n","       'Fuel_Type', 'Seller_Type', 'Transmission', 'Owner'],\n","      dtype='object')\n","\n","Columns to drop not found in the dataset.\n"]}],"source":["import pandas as pd\n","\n","# Load the dataset\n","file_path = \"C:/Users/hp/Downloads/car+data.csv\"\n","df = pd.read_csv(file_path)\n","\n","# Display the columns to identify which ones are redundant\n","print(\"Original columns:\")\n","print(df.columns)\n","\n","# List of columns to drop (example of redundant columns)\n","columns_to_drop = ['Column1', 'Column2', 'Column3']\n","\n","# Check if columns_to_drop exist in df.columns before dropping\n","columns_to_drop_existing = [col for col in columns_to_drop if col in df.columns]\n","\n","if columns_to_drop_existing:\n","    # Drop the redundant columns\n","    df.drop(columns=columns_to_drop_existing, inplace=True)\n","    print(\"\\nColumns after dropping redundant columns:\")\n","    print(df.columns)\n","else:\n","    print(\"\\nColumns to drop not found in the dataset.\")\n","\n","# Optionally, you can save the modified dataset back to a file if needed\n","# df.to_csv(\"updated_car_data.csv\", index=False)\n"]},{"cell_type":"markdown","id":"7fb3674f","metadata":{"id":"7fb3674f"},"source":["### 6. Extract a new feature called 'age_of_the_car' from the feature 'year' and drop the feature year"]},{"cell_type":"code","execution_count":7,"id":"-E8ZwwvE7Oe_","metadata":{"id":"-E8ZwwvE7Oe_"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original columns:\n","Index(['Car_Name', 'Year', 'Selling_Price', 'Present_Price', 'Kms_Driven',\n","       'Fuel_Type', 'Seller_Type', 'Transmission', 'Owner'],\n","      dtype='object')\n","Column 'year' not found in the dataset. Verify the column name or dataset contents.\n"]}],"source":["import pandas as pd\n","import datetime as dt\n","\n","# Load the dataset\n","file_path = \"C:/Users/hp/Downloads/car+data.csv\"\n","df = pd.read_csv(file_path)\n","\n","# Display the columns to understand the structure\n","print(\"Original columns:\")\n","print(df.columns)\n","\n","# Check if 'year' or equivalent column exists\n","if 'year' in df.columns:\n","    # Calculate current year\n","    current_year = dt.datetime.now().year\n","\n","    # Calculate age of the car\n","    df['age_of_the_car'] = current_year - df['year']\n","\n","    # Drop the 'year' column\n","    df.drop(columns=['year'], inplace=True)\n","\n","    # Display the updated columns after dropping 'year'\n","    print(\"\\nColumns after dropping 'year' and adding 'age_of_the_car':\")\n","    print(df.columns)\n","\n","    # Optionally, you can save the modified dataset back to a file if needed\n","    # df.to_csv(\"updated_car_data.csv\", index=False)\n","else:\n","    print(\"Column 'year' not found in the dataset. Verify the column name or dataset contents.\")\n"]},{"cell_type":"markdown","id":"8f3a144b","metadata":{"id":"8f3a144b"},"source":["### 7. Encode the categorical columns"]},{"cell_type":"code","execution_count":9,"id":"EUwBNILZ7PT9","metadata":{"id":"EUwBNILZ7PT9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original columns:\n","Index(['Car_Name', 'Year', 'Selling_Price', 'Present_Price', 'Kms_Driven',\n","       'Fuel_Type', 'Seller_Type', 'Transmission', 'Owner'],\n","      dtype='object')\n","No valid categorical columns found in the dataset.\n"]}],"source":["import pandas as pd\n","\n","# Load the dataset\n","file_path = \"C:/Users/hp/Downloads/car+data.csv\"\n","df = pd.read_csv(file_path)\n","\n","# Display the columns to identify categorical variables\n","print(\"Original columns:\")\n","print(df.columns)\n","\n","# Replace with actual categorical column names\n","categorical_columns = ['ActualCategoricalColumn1', 'ActualCategoricalColumn2']\n","\n","# Check if categorical columns exist in df.columns\n","existing_categorical_columns = [col for col in categorical_columns if col in df.columns]\n","\n","if existing_categorical_columns:\n","    # One-hot encode categorical columns\n","    df_encoded = pd.get_dummies(df, columns=existing_categorical_columns, drop_first=True)\n","\n","    # Display the updated columns after encoding\n","    print(\"\\nColumns after encoding categorical columns:\")\n","    print(df_encoded.columns)\n","\n","    # Optionally, you can save the encoded dataset back to a file if needed\n","    # df_encoded.to_csv(\"encoded_car_data.csv\", index=False)\n","else:\n","    print(\"No valid categorical columns found in the dataset.\")\n","\n"]},{"cell_type":"markdown","id":"8afe4984","metadata":{"id":"8afe4984"},"source":["### 8. Separate the target and independent features."]},{"cell_type":"code","execution_count":11,"id":"39E39X1y7Pvq","metadata":{"id":"39E39X1y7Pvq"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original columns:\n","Index(['Car_Name', 'Year', 'Selling_Price', 'Present_Price', 'Kms_Driven',\n","       'Fuel_Type', 'Seller_Type', 'Transmission', 'Owner'],\n","      dtype='object')\n","Target column 'actual_target_column_name' not found in the dataset. Verify column name.\n"]}],"source":["import pandas as pd\n","\n","# Load the dataset\n","file_path = \"C:/Users/hp/Downloads/car+data.csv\"\n","df = pd.read_csv(file_path)\n","\n","# Display the columns to understand the structure\n","print(\"Original columns:\")\n","print(df.columns)\n","\n","# Example: Assuming 'target_column' is your target variable (replace with actual target column name)\n","target_column = 'actual_target_column_name'\n","\n","# Check if the target column exists in the DataFrame\n","if target_column in df.columns:\n","    # Separate the target variable (dependent feature) and independent features\n","    y = df[target_column]  # Target variable\n","    X = df.drop(columns=[target_column])  # Independent features\n","\n","    # Display the shapes of X and y to verify separation\n","    print(\"\\nShape of X (independent features):\", X.shape)\n","    print(\"Shape of y (target variable):\", y.shape)\n","else:\n","    print(f\"Target column '{target_column}' not found in the dataset. Verify column name.\")\n","\n"]},{"cell_type":"markdown","id":"e12c5ef9","metadata":{"id":"e12c5ef9"},"source":["### 9. Split the data into train and test."]},{"cell_type":"code","execution_count":13,"id":"gvxCw7PF7Qon","metadata":{"id":"gvxCw7PF7Qon"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original columns:\n","Index(['Car_Name', 'Year', 'Selling_Price', 'Present_Price', 'Kms_Driven',\n","       'Fuel_Type', 'Seller_Type', 'Transmission', 'Owner'],\n","      dtype='object')\n","Target column 'actual_target_column_name' not found in the dataset. Verify column name.\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Load the dataset\n","file_path = \"C:/Users/hp/Downloads/car+data.csv\"\n","df = pd.read_csv(file_path)\n","\n","# Display the columns to understand the structure\n","print(\"Original columns:\")\n","print(df.columns)\n","\n","# Replace with the actual name of your target variable column\n","target_column = 'actual_target_column_name'\n","\n","# Check if the target column exists in the DataFrame\n","if target_column in df.columns:\n","    # Separate the target variable (dependent feature) and independent features\n","    y = df[target_column]  # Target variable\n","    X = df.drop(columns=[target_column])  # Independent features\n","\n","    # Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","    # Print the shapes of the train and test sets to verify\n","    print(\"Shape of X_train:\", X_train.shape)\n","    print(\"Shape of X_test:\", X_test.shape)\n","    print(\"Shape of y_train:\", y_train.shape)\n","    print(\"Shape of y_test:\", y_test.shape)\n","else:\n","    print(f\"Target column '{target_column}' not found in the dataset. Verify column name.\")\n"]},{"cell_type":"markdown","id":"e86fbc33","metadata":{"id":"e86fbc33"},"source":["### 10. Build a Random forest Regressor model and check the r2-score for train and test."]},{"cell_type":"code","execution_count":14,"id":"IiEKH-kh7Rsw","metadata":{"id":"IiEKH-kh7Rsw"},"outputs":[{"name":"stdout","output_type":"stream","text":["Target column 'target_variable' not found in the dataset. Verify column name.\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import r2_score\n","\n","# Load the dataset\n","file_path = \"C:/Users/hp/Downloads/car+data.csv\"\n","df = pd.read_csv(file_path)\n","\n","# Assuming 'target_column' is your target variable\n","target_column = 'target_variable'  # Replace with actual target column name\n","\n","# Check if the target column exists in the DataFrame\n","if target_column in df.columns:\n","    # Separate the target variable (dependent feature) and independent features\n","    y = df[target_column]  # Target variable\n","    X = df.drop(columns=[target_column])  # Independent features\n","\n","    # Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","    # Build the Random Forest Regressor model\n","    rf_regressor = RandomForestRegressor(random_state=42)\n","\n","    # Train the model\n","    rf_regressor.fit(X_train, y_train)\n","\n","    # Predict on training and test sets\n","    y_train_pred = rf_regressor.predict(X_train)\n","    y_test_pred = rf_regressor.predict(X_test)\n","\n","    # Calculate R^2 score for training and test sets\n","    r2_train = r2_score(y_train, y_train_pred)\n","    r2_test = r2_score(y_test, y_test_pred)\n","\n","    # Print R^2 scores\n","    print(f\"R^2 score on training set: {r2_train:.2f}\")\n","    print(f\"R^2 score on test set: {r2_test:.2f}\")\n","\n","else:\n","    print(f\"Target column '{target_column}' not found in the dataset. Verify column name.\")\n"]},{"cell_type":"markdown","id":"ab525b11","metadata":{"id":"ab525b11"},"source":["### 11. Create a pickle file with an extension as .pkl"]},{"cell_type":"code","execution_count":15,"id":"jLj3VeCH7Spb","metadata":{"id":"jLj3VeCH7Spb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved pickle file to 'model.pkl'\n"]}],"source":["import pickle\n","\n","# Example dictionary (replace with your object, e.g., trained model)\n","data = {'name': 'John', 'age': 30, 'city': 'New York'}\n","\n","# Path to save the .pkl file\n","file_path = 'model.pkl'\n","\n","# Write to the .pkl file\n","with open(file_path, 'wb') as file:\n","    pickle.dump(data, file)\n","\n","print(f\"Saved pickle file to '{file_path}'\")\n"]},{"cell_type":"markdown","id":"26246dc9","metadata":{"id":"26246dc9"},"source":["### 12. Create new folder/new project in visual studio/pycharm that should contain the \"model.pkl\" file *make sure you are using a virutal environment and install required packages.*"]},{"cell_type":"markdown","id":"0f2bd8b3","metadata":{"id":"0f2bd8b3"},"source":["### a) Create a basic HTML form for the frontend"]},{"cell_type":"markdown","id":"d5a3da56","metadata":{"id":"d5a3da56"},"source":["Create a file **index.html** in the templates folder and copy the following code."]},{"cell_type":"code","execution_count":null,"id":"l6E1gBAZ7UD4","metadata":{"id":"l6E1gBAZ7UD4"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"ab774e57","metadata":{"id":"ab774e57"},"source":["### b) Create app.py file and write the predict function"]},{"cell_type":"code","execution_count":17,"id":"9r3rWra57UuQ","metadata":{"id":"9r3rWra57UuQ"},"outputs":[{"name":"stdout","output_type":"stream","text":[" * Serving Flask app '__main__'\n"," * Debug mode: on\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n"," * Running on http://127.0.0.1:5000\n","Press CTRL+C to quit\n"," * Restarting with stat\n"]},{"ename":"SystemExit","evalue":"1","output_type":"error","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\hp\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}],"source":["from flask import Flask, request, jsonify\n","\n","# Initialize Flask application\n","app = Flask(__name__)\n","\n","# Sample prediction function (replace with your actual prediction logic)\n","def predict(input_data):\n","    # Sample logic (replace with your actual model prediction)\n","    result = {'prediction': 'Sample prediction result'}\n","    return result\n","\n","# Define a route for prediction\n","@app.route('/predict', methods=['POST'])\n","def predict_route():\n","    try:\n","        # Get data from request\n","        input_data = request.json\n","        \n","        # Call prediction function\n","        prediction_result = predict(input_data)\n","        \n","        # Return prediction result as JSON response\n","        return jsonify(prediction_result), 200\n","    except Exception as e:\n","        # Handle exceptions\n","        return jsonify({'error': str(e)}), 400\n","\n","# Run the application\n","if __name__ == '__main__':\n","    app.run(debug=True)\n"]},{"cell_type":"markdown","id":"CBewpqT7MEbb","metadata":{"id":"CBewpqT7MEbb"},"source":["### 13. Run the app.py python file which will render to index html page then enter the input values and get the prediction."]},{"cell_type":"code","execution_count":18,"id":"8g7gvFyD7VHN","metadata":{"id":"8g7gvFyD7VHN"},"outputs":[{"name":"stdout","output_type":"stream","text":[" * Serving Flask app '__main__'\n"," * Debug mode: on\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n"," * Running on http://127.0.0.1:5000\n","Press CTRL+C to quit\n"," * Restarting with stat\n"]},{"ename":"SystemExit","evalue":"1","output_type":"error","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"]}],"source":["from flask import Flask, render_template, request, jsonify\n","\n","# Initialize Flask application\n","app = Flask(__name__)\n","\n","# Sample prediction function (replace with your actual prediction logic)\n","def predict(input_data):\n","    # Sample logic (replace with your actual model prediction)\n","    result = {'prediction': 'Sample prediction result'}\n","    return result\n","\n","# Route to render index.html\n","@app.route('/')\n","def home():\n","    return render_template('index.html')\n","\n","# Route to handle prediction\n","@app.route('/predict', methods=['POST'])\n","def predict_route():\n","    try:\n","        # Get data from request\n","        input_data = request.form  # Use request.form to get form data\n","        \n","        # Call prediction function\n","        prediction_result = predict(input_data)\n","        \n","        # Return prediction result as JSON response\n","        return jsonify(prediction_result), 200\n","    except Exception as e:\n","        # Handle exceptions\n","        return jsonify({'error': str(e)}), 400\n","\n","# Run the application\n","if __name__ == '__main__':\n","    app.run(debug=True)\n"]},{"cell_type":"markdown","id":"e899b5a2","metadata":{"id":"e899b5a2"},"source":["### Happy Learning :)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":5}
